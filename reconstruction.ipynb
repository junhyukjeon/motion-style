{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9577bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/salad/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from salad.t2m import Text2Motion\n",
    "from salad.utils.get_opt import get_opt\n",
    "\n",
    "from salad.utils.fixseed import fixseed\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import torch\n",
    "import numpy as np\n",
    "from salad.utils.motion_process import recover_from_ric\n",
    "from salad.utils.plot_script import plot_3d_motion\n",
    "from salad.utils.get_opt import get_opt\n",
    "\n",
    "from salad.data.t2m_dataset import MotionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def plot_t2m(data, text, filename):\n",
    "    os.makedirs(\"reconstruction_result\", exist_ok=True)\n",
    "    #data = data[:m_lens[0].item()]\n",
    "    data = data\n",
    "    joint = recover_from_ric(torch.from_numpy(data).float(), opt.joints_num).numpy()\n",
    "    save_path = pjoin(\"reconstruction_result\", f\"{filename}.mp4\")\n",
    "    plot_3d_motion(save_path, opt.kinematic_chain, joint, title=text, fps=20)\n",
    "\n",
    "    np.save(pjoin(\"reconstruction_result\", f\"{filename}_pos.npy\"), joint)\n",
    "    np.save(pjoin(\"reconstruction_result\", f\"{filename}_feats.npy\"), data)\n",
    "\n",
    "def plot_og(motion_path, text, filename):\n",
    "    os.makedirs(\"og_result\", exist_ok=True)\n",
    "    joint = np.load(motion_path)[:260]\n",
    "    print(joint.shape)\n",
    "    save_path = pjoin(\"og_result\", f\"{filename}.mp4\")\n",
    "    plot_3d_motion(save_path, opt.kinematic_chain, joint, title=text, fps=20)\n",
    "    np.save(pjoin(\"og_result\", f\"{filename}_pos.npy\"), joint)\n",
    "    # np.save(pjoin(\"og_result\", f\"{filename}_feats.npy\"), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b7c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading checkpoints/t2m/t2m_denoiser_vpred_vaegelu/opt.txt\n",
      "Reading checkpoints/t2m/t2m_vae_gelu/opt.txt\n",
      "Loading VAE Model t2m_vae_gelu\n",
      "Loading Denoiser Model t2m_denoiser_vpred_vaegelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CLIP text encoder version ViT-B/32\n"
     ]
    }
   ],
   "source": [
    "denoiser_name = \"t2m_denoiser_vpred_vaegelu\"\n",
    "dataset_name = \"t2m\"\n",
    "model = Text2Motion(denoiser_name, dataset_name)\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068d6bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./checkpoints/t2m/Comp_v6_KLD005/opt.txt\n"
     ]
    }
   ],
   "source": [
    "data_opt = get_opt(model.opt.dataset_opt_path, torch.device('cuda'))\n",
    "mean = np.load(pjoin(data_opt.meta_dir, 'mean.npy'))\n",
    "std = np.load(pjoin(data_opt.meta_dir, 'std.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ee4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16074 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16074/16074 [00:06<00:00, 2449.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 14136, snippets 3037678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = model.vae_opt\n",
    "data = MotionDataset(opt, mean, std, './dataset/100style/100style.txt')\n",
    "dataloader = DataLoader(data, batch_size=1, drop_last=True, num_workers=opt.num_workers, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions = []\n",
    "for i, batch in enumerate(dataloader):\n",
    "    batch  = batch.to(device, dtype=torch.float32)\n",
    "    z, _   = model.vae.encode(batch)\n",
    "    motion = model.vae.decode(z)\n",
    "    motions.append(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64fc58d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "motion_id = open(f'./dataset/100style/100style.txt').readlines()[0].strip()\n",
    "src_motion = motions[0].detach().cpu().numpy() * std + mean\n",
    "plot_t2m(src_motion[0], \"recon\", \"src\")\n",
    "plot_og(f'./dataset/100style/new_joints/{motion_id}.npy', \"og\", \"og\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video reconstruction_result/final.mp4.\n",
      "Moviepy - Writing video reconstruction_result/final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready reconstruction_result/final.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"reconstruction_result/final.mp4\" controls  width=\"800\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, clips_array\n",
    "og_video = VideoFileClip(pjoin(\"delete\", \"1.mp4\"))\n",
    "src_video = VideoFileClip(pjoin(\"delete\", \"2.mp4\"))\n",
    "final_video = clips_array([[og_video, src_video]])\n",
    "final_video.write_videofile(pjoin(\"reconstruction_result\", \"final.mp4\"))\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(\"reconstruction_result/final.mp4\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "82871833",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint1 = np.load('./reconstruction_result/src_pos.npy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed1650fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint2 = np.load(f'./dataset/100style/new_joints/{motion_id}.npy')[:260]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
