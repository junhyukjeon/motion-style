# This one is FiLM instead of LoRA into SALAD's cross attention.
# --- Run Management --- #
run_name: auto
result_dir: ./results
checkpoint_dir: ./checkpoints/t2sm
random_seed: 42

# --- Dataset --- #
dataset_style:
  motion_dir  : ./dataset/100style/new_joint_vecs
  text_dir    : ./dataset/100style/texts
  mean_path   : ./checkpoints/t2m/Comp_v6_KLD005/meta/mean.npy
  std_path    : ./checkpoints/t2m/Comp_v6_KLD005/meta/std.npy
  style_json  : ./dataset/100style/100style_smoodi.json
  content_json: ./dataset/100style/10content_smoodi.json
  unit_length : 4
  min_frames  : 40
  max_frames  : 196
  drop_first_frame: True
  unit_double_prob: 0.3333

dataset_hml:
  split_base_train: ./dataset/humanml3d/train_random_humanml.txt
  split_base_valid: ./dataset/humanml3d/valid_random_humanml.txt
  mean_path       : ./checkpoints/t2m/Comp_v6_KLD005/meta/mean.npy
  std_path        : ./checkpoints/t2m/Comp_v6_KLD005/meta/std.npy
  unit_length     : 4
  min_frames      : 40
  max_frames      : 196

# --- Sampler Settings --- #
sampler:
  type: TrainSampler
  batch_size: 32
  # samples_per_style: 4

# --- Model --- #
model:
  denoiser:
    transformer:
      layer:
        attention: {}
        film:
          lora:
            type: HyperLoRA
            rank: 8
            scale: 1.0
            style_dim: 256
            num_layers: 4
            in_dim: 256
            out_dim: 512
            hidden_dim: 512
            block:
              dropout: 0.1
              style_dim: 256
              hidden_dim: 512
              num_heads: 8
  style_encoder:
    type: StyleMLP
    dropout: 0.1
    style_dim: 256
    num_layers: 4
    block:
      dropout: 0.1
      style_dim: 256
      hidden_dim: 512
      num_heads: 8
      repeats: 2
  text_drop: 0.1
  style_drop: 0.1
  text_weight: 7.5
  style_weight: 2.5

# --- Losses --- #
loss:
  style: 
    weight: 1.0
  # content:
  #   weight: 1.0
  cycle:
    weight: 1.0
  supcon:
    weight: 1.0
    temperature: 0.07

# --- Early Stopper --- #
early:
  patience: 10
  min_delta: 0.0
  mode: min

# --- Calibration --- #
steps: 34
tau: 0.001

# --- Training --- #
epochs: 300
lr: 0.0002
valid_size: 0.0